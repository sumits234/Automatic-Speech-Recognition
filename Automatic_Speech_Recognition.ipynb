{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93d3add8da3e48fb81ba67a8833b722b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b752200f71b4ff6b85bda18f3ddf884",
              "IPY_MODEL_ed6fa952d79440edb2c1d4d8f6cf74b5",
              "IPY_MODEL_751a06f18a4946958d28c163e4b5cbaf"
            ],
            "layout": "IPY_MODEL_19edb72ae1384804ae6eecb2cd9c9a15"
          }
        },
        "4b752200f71b4ff6b85bda18f3ddf884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1575e53fa71421fb00ee0ee59db9263",
            "placeholder": "​",
            "style": "IPY_MODEL_3b29b75669884e77a2db3e0dd94e96de",
            "value": "Map (num_proc=4): 100%"
          }
        },
        "ed6fa952d79440edb2c1d4d8f6cf74b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec0fa2825aa74ed081eb80749766a463",
            "max": 2620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d08622de775e417980bcecab23ef558e",
            "value": 2620
          }
        },
        "751a06f18a4946958d28c163e4b5cbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fb25084c9d43aa87949374094d6bc8",
            "placeholder": "​",
            "style": "IPY_MODEL_19279e8654f941c4b0bab95c91e15ca6",
            "value": " 2620/2620 [00:42&lt;00:00, 33.24 examples/s]"
          }
        },
        "19edb72ae1384804ae6eecb2cd9c9a15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1575e53fa71421fb00ee0ee59db9263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b29b75669884e77a2db3e0dd94e96de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec0fa2825aa74ed081eb80749766a463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d08622de775e417980bcecab23ef558e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63fb25084c9d43aa87949374094d6bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19279e8654f941c4b0bab95c91e15ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5070204b9f2462f9c04210a1edb0afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6b6e2223d3d443ea42f7e66fc3312de",
              "IPY_MODEL_474994f8c7954fa9a74ba11c2f65a3c5",
              "IPY_MODEL_60712fc6545c411e8b859a2a41cc42c6"
            ],
            "layout": "IPY_MODEL_611003a42b3d45deb1cdfb9368161a63"
          }
        },
        "a6b6e2223d3d443ea42f7e66fc3312de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cffb94c7c042462e86d785a93a7c71d0",
            "placeholder": "​",
            "style": "IPY_MODEL_4538fb65ba9c4d60ab84e62266490256",
            "value": "Map: 100%"
          }
        },
        "474994f8c7954fa9a74ba11c2f65a3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c98c462feae44db5afac21867ddbb070",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6819e6d566db4a03aef4a7e8a3dde232",
            "value": 2000
          }
        },
        "60712fc6545c411e8b859a2a41cc42c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e4cfd8c4aba4f848615da7b23213bc6",
            "placeholder": "​",
            "style": "IPY_MODEL_04b03ed2bda34fdba3009d298168245b",
            "value": " 2000/2000 [00:44&lt;00:00,  2.86 examples/s]"
          }
        },
        "611003a42b3d45deb1cdfb9368161a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cffb94c7c042462e86d785a93a7c71d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4538fb65ba9c4d60ab84e62266490256": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c98c462feae44db5afac21867ddbb070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6819e6d566db4a03aef4a7e8a3dde232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e4cfd8c4aba4f848615da7b23213bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b03ed2bda34fdba3009d298168245b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a4780fdba5b44bca5e1f004bd79f11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20004c322b824beba0539b58940a58b1",
              "IPY_MODEL_9bf3fdd6a7ca4b349dd3fc2c3a9c5bed",
              "IPY_MODEL_7b98b3af362946939d33369905142e4f"
            ],
            "layout": "IPY_MODEL_10bf43ce346149f9bf60b2df8b572dc6"
          }
        },
        "20004c322b824beba0539b58940a58b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf19db67a7bc44899dcd274a5bd843a2",
            "placeholder": "​",
            "style": "IPY_MODEL_a5c052b32bce4cab8511ce36155fd9ed",
            "value": "Map: 100%"
          }
        },
        "9bf3fdd6a7ca4b349dd3fc2c3a9c5bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4f8e0ad3604546bbd24f0be110b5b9",
            "max": 2620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c92c4fd8ca0435988e025a2861eeaaf",
            "value": 2620
          }
        },
        "7b98b3af362946939d33369905142e4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d08a4fbde89840bdabc65e8d85bb60d6",
            "placeholder": "​",
            "style": "IPY_MODEL_d21a395592f343e789907fdf8e14078d",
            "value": " 2620/2620 [00:16&lt;00:00, 255.83 examples/s]"
          }
        },
        "10bf43ce346149f9bf60b2df8b572dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf19db67a7bc44899dcd274a5bd843a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c052b32bce4cab8511ce36155fd9ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac4f8e0ad3604546bbd24f0be110b5b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c92c4fd8ca0435988e025a2861eeaaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d08a4fbde89840bdabc65e8d85bb60d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d21a395592f343e789907fdf8e14078d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumits234/Automatic-Speech-Recognition/blob/main/Automatic_Speech_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw0nz2sB2Gzc",
        "outputId": "18779fc0-be8f-4cd6-ebf6-0d8ca635dc69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# === Cell 1: Mount Google Drive ===\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCF7EbRkdm_G",
        "outputId": "764b188d-d0f8-42bc-aa80-4e34263c10a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.40.1)\n",
            "Collecting transformers\n",
            "  Using cached transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Using cached transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.1\n",
            "    Uninstalling transformers-4.40.1:\n",
            "      Successfully uninstalled transformers-4.40.1\n",
            "Successfully installed tokenizers-0.21.1 transformers-4.52.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We'll use: torchaudio, datasets, transformers, evaluate, soundfile, fastapi, uvicorn\n",
        "\n",
        "!pip install --quiet torchaudio datasets transformers evaluate soundfile fastapi uvicorn\n"
      ],
      "metadata": {
        "id": "GZW5nOPE2wan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Define Paths & Imports\n",
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from torchaudio.datasets import LIBRISPEECH\n",
        "from transformers import (\n",
        "    Wav2Vec2Processor,\n",
        "    Wav2Vec2ForCTC,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "\n",
        ")\n",
        "from datasets import load_metric, Dataset, Audio\n",
        "import numpy as np\n",
        "import random\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "xLonuyG34Mlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 3: Extract both train-clean-100 and test-clean ===\n",
        "\n",
        "# 3.1 Ensure target local folder exists\n",
        "!rm -rf /content/LibriSpeech           # Start fresh to avoid duplication\n",
        "!mkdir -p /content/LibriSpeech\n",
        "\n",
        "# 3.2 Extract train-clean-100.tar.gz\n",
        "# This will extract /content/LibriSpeech/train-clean-100\n",
        "!tar -xzf \"/content/drive/MyDrive/LibriSpeech/train-clean-100.tar.gz\" -C /content\n",
        "\n",
        "# 3.3 Extract test-clean.tar.gz\n",
        "# This will extract /content/LibriSpeech/test-clean\n",
        "!tar -xzf \"/content/drive/MyDrive/LibriSpeech/test-clean.tar.gz\" -C /content\n",
        "\n",
        "# 3.4 After extraction, everything should now be in:\n",
        "# /content/LibriSpeech/train-clean-100/\n",
        "# /content/LibriSpeech/test-clean/\n",
        "\n",
        "# 3.5 Confirm folder structure\n",
        "!echo \"✅ Extraction complete. Contents of /content/LibriSpeech:\"\n",
        "!ls -l /content/LibriSpeech\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_d5CUgb5bjg",
        "outputId": "24903836-1b00-4b6a-f276-e97f87227ef9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extraction complete. Contents of /content/LibriSpeech:\n",
            "total 916\n",
            "-rw-r--r--   1 1000 1000 115746 Oct  3  2014 BOOKS.TXT\n",
            "-rw-r--r--   1 1000 1000 671086 Aug 17  2014 CHAPTERS.TXT\n",
            "-rw-r--r--   1 1000 1000    193 Aug 17  2014 LICENSE.TXT\n",
            "-rw-r--r--   1 1000 1000   8039 Oct  3  2014 README.TXT\n",
            "-rw-r--r--   1 1000 1000 125034 Aug 17  2014 SPEAKERS.TXT\n",
            "drwxr-xr-x  42 1000 1000   4096 Aug 16  2014 test-clean\n",
            "drwxr-xr-x 253 1000 1000   4096 Aug 16  2014 train-clean-100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 4: Confirm the LOCAL folders and set paths for the rest of the notebook ===\n",
        "import os\n",
        "\n",
        "LIBRISPEECH_ROOT = \"/content/LibriSpeech\"\n",
        "TRAIN_SUBSET     = os.path.join(LIBRISPEECH_ROOT, \"train-clean-100\")\n",
        "TEST_SUBSET      = os.path.join(LIBRISPEECH_ROOT, \"test-clean\")\n",
        "\n",
        "print(\"Contents of /content/LibriSpeech:\\n\", os.listdir(LIBRISPEECH_ROOT), \"\\n\")\n",
        "print(\"TRAIN_SUBSET =\", TRAIN_SUBSET, \"→\", \"\" if os.path.isdir(TRAIN_SUBSET) else \"NOT FOUND\")\n",
        "print(\"TEST_SUBSET  =\", TEST_SUBSET,  \"→\", \"\" if os.path.isdir(TEST_SUBSET)  else \" NOT FOUND\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMUUXM0J2weG",
        "outputId": "df01b328-f1d1-4a84-e336-d3b4bba6b7a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of /content/LibriSpeech:\n",
            " ['CHAPTERS.TXT', 'LICENSE.TXT', 'BOOKS.TXT', 'SPEAKERS.TXT', 'train-clean-100', 'test-clean', 'README.TXT'] \n",
            "\n",
            "TRAIN_SUBSET = /content/LibriSpeech/train-clean-100 → \n",
            "TEST_SUBSET  = /content/LibriSpeech/test-clean → \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "print(\"Ready to proceed with Dataset exploration and model training.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbWLV7aDA1bY",
        "outputId": "0d01b498-4daa-4b46-8637-a161d5eff5be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to proceed with Dataset exploration and model training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# == — Basic Exploration of train-clean-100 & test-clean ===\n",
        "import soundfile as sf\n",
        "from pathlib import Path\n",
        "from torchaudio.datasets import LIBRISPEECH\n",
        "\n",
        "def gather_stats(path):\n",
        "    n_files = 0\n",
        "    total_duration = 0.0\n",
        "    for flac in Path(path).rglob(\"*.flac\"):\n",
        "        n_files += 1\n",
        "        info = sf.info(str(flac))\n",
        "        total_duration += info.frames / info.samplerate\n",
        "    return n_files, total_duration\n",
        "\n",
        "# The on-disk structure is /content/LibriSpeech/train-clean-100 and /content/LibriSpeech/test-clean\n",
        "TRAIN_SUBSET = \"/content/LibriSpeech/train-clean-100\"\n",
        "TEST_SUBSET  = \"/content/LibriSpeech/test-clean\"\n",
        "\n",
        "# 1. Count files & total duration\n",
        "train_n, train_dur = gather_stats(TRAIN_SUBSET)\n",
        "test_n,  test_dur  = gather_stats(TEST_SUBSET)\n",
        "\n",
        "print(f\"Train-clean-100: {train_n} audio files, ≈{train_dur/3600:.2f} hours\")\n",
        "print(f\"Test-clean:      {test_n} audio files, ≈{test_dur/3600:.2f} hours\")\n",
        "\n",
        "# 2. Sample transcript lengths from train-clean-100 via torchaudio’s LIBRISPEECH loader\n",
        "#    Here we set root=\"/content\" so that LIBRISPEECH can find \"/content/LibriSpeech/train-clean-100\".\n",
        "loader_train = LIBRISPEECH(root=\"/content\", url=\"train-clean-100\", download=False)\n",
        "lengths = []\n",
        "for i, (_, _, transcript, *_ ) in enumerate(loader_train):\n",
        "    if i >= 100:\n",
        "        break\n",
        "    lengths.append(len(transcript.split()))\n",
        "\n",
        "import numpy as _np\n",
        "print(f\"Sample transcripts (n=100): avg words={_np.mean(lengths):.1f}, min={_np.min(lengths)}, max={_np.max(lengths)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLZphYJwA5Bt",
        "outputId": "be09802a-1c1c-4211-9ff8-d642d8877628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train-clean-100: 28539 audio files, ≈100.59 hours\n",
            "Test-clean:      2620 audio files, ≈5.40 hours\n",
            "Sample transcripts (n=100): avg words=48.1, min=15, max=68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell 7: Task 2 — Load Pretrained Wav2Vec2 & Compute Baseline WER ===\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDpq7O02A5Ec",
        "outputId": "128092e6-71ec-40ab-91bc-40dcacf432d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for the test-clean directory\n",
        "!ls \"/content/LibriSpeech\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLT6q4WeEPrR",
        "outputId": "a85eda65-4e22-429b-bbf4-6977ebb583c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BOOKS.TXT     LICENSE.TXT  SPEAKERS.TXT  train-clean-100\n",
            "CHAPTERS.TXT  README.TXT   test-clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LIBRISPEECH_ROOT = \"/content\"\n",
        "TEST_SUBSET      = \"/content/LibriSpeech/test-clean\"\n"
      ],
      "metadata": {
        "id": "g_gKiQinEgvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/LibriSpeech/test-clean/0121/121726\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XojmUh0TEqcx",
        "outputId": "c33beed6-5fec-4881-e79c-14f3103358e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/LibriSpeech/test-clean/0121/121726': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List the top‐level inside test-clean\n",
        "!ls \"/content/LibriSpeech/test-clean\"\n",
        "\n",
        "# Then, for example, list the contents of speaker “121”:\n",
        "!ls \"/content/LibriSpeech/test-clean/121\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02igO1vDE1Qg",
        "outputId": "480a84f3-2348-4029-93dd-cff3d97910c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1089  1284  2094  2830\t3729  4970  5639  6829\t7176  8455\n",
            "1188  1320  2300  2961\t4077  4992  5683  6930\t7729  8463\n",
            "121   1580  237   3570\t4446  5105  61\t  7021\t8224  8555\n",
            "1221  1995  260   3575\t4507  5142  672   7127\t8230  908\n",
            "121726\t123852\t123859\t127105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEYV5ofFFqur",
        "outputId": "dcc5ac83-50d9-4b47-bdab-ad391353519c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.2.1)\n",
            "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Baseline WER on test-clean  ===\n",
        "LIBRISPEECH_ROOT = \"/content\"\n",
        "TEST_SUBSET      = \"/content/LibriSpeech/test-clean\"\n",
        "\n",
        "# 2) Load pretrained model + processor\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name).to(\n",
        "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "print(\"Loaded pretrained Wav2Vec2 model and processor.\\n\")\n",
        "\n",
        "# 3) Build a pandas DataFrame for test-clean\n",
        "test_rows = []\n",
        "loader_test = LIBRISPEECH(root=LIBRISPEECH_ROOT, url=\"test-clean\", download=False)\n",
        "\n",
        "for waveform, sr, transcript, speaker_id, chapter_id, utterance_id in loader_test:\n",
        "    # ──► Use speaker_id and chapter_id as plain ints (no zero-padding in folder names)\n",
        "    spk_folder = str(speaker_id)\n",
        "    chp_folder = str(chapter_id)\n",
        "    # ──► Zero-pad only the utterance_id to 4 digits for the filename\n",
        "    filename = f\"{speaker_id}-{chapter_id}-{utterance_id:04d}.flac\"\n",
        "    flac_path = os.path.join(TEST_SUBSET, spk_folder, chp_folder, filename)\n",
        "    test_rows.append({\"audio_path\": flac_path, \"transcript\": transcript})\n",
        "\n",
        "test_df = pd.DataFrame(test_rows)\n",
        "dataset_test = Dataset.from_pandas(test_df)\n",
        "dataset_test = dataset_test.cast_column(\"audio_path\", Audio(sampling_rate=16000))\n",
        "dataset_test = dataset_test.rename_column(\"audio_path\", \"audio\")\n",
        "dataset_test = dataset_test.rename_column(\"transcript\", \"text\")\n",
        "print(f\" Built dataset_test with {len(dataset_test)} utterances.\\n\")\n",
        "\n",
        "# 4) Preprocessing function: waveform → input_values; transcript → labels\n",
        "def prepare_batch(batch):\n",
        "    audio = batch[\"audio\"][\"array\"]\n",
        "    batch[\"input_values\"] = processor(audio, sampling_rate=16000).input_values[0]\n",
        "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "dataset_test = dataset_test.map(\n",
        "    prepare_batch,\n",
        "    remove_columns=[\"audio\", \"text\"],\n",
        "    num_proc=4\n",
        ")\n",
        "print(\" Preprocessing complete (mapped input_values + labels).\\n\")\n",
        "\n",
        "# 5) Run inference & compute WER in batches (with padding)\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "predictions = []\n",
        "references = []\n",
        "batch_size = 8\n",
        "\n",
        "for i in range(0, len(dataset_test), batch_size):\n",
        "    batch = dataset_test[i : i + batch_size]\n",
        "\n",
        "    # Pad input_values correctly\n",
        "    input_features = [{\"input_values\": x} for x in batch[\"input_values\"]]\n",
        "    padded_inputs = processor.feature_extractor.pad(\n",
        "        input_features,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_values = padded_inputs[\"input_values\"].to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "\n",
        "    pred_ids = torch.argmax(logits, dim=-1)\n",
        "    preds = processor.batch_decode(pred_ids)\n",
        "\n",
        "    # Decode references (labels)\n",
        "    label_ids = batch[\"labels\"]\n",
        "    references_batch = processor.batch_decode(label_ids, group_tokens=False)\n",
        "\n",
        "    predictions.extend(preds)\n",
        "    references.extend(references_batch)\n",
        "\n",
        "# Final WER score\n",
        "baseline_wer = wer_metric.compute(predictions=predictions, references=references)\n",
        "print(f\"\\n Baseline WER (pretrained {model_name}): {baseline_wer:.3f}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "93d3add8da3e48fb81ba67a8833b722b",
            "4b752200f71b4ff6b85bda18f3ddf884",
            "ed6fa952d79440edb2c1d4d8f6cf74b5",
            "751a06f18a4946958d28c163e4b5cbaf",
            "19edb72ae1384804ae6eecb2cd9c9a15",
            "d1575e53fa71421fb00ee0ee59db9263",
            "3b29b75669884e77a2db3e0dd94e96de",
            "ec0fa2825aa74ed081eb80749766a463",
            "d08622de775e417980bcecab23ef558e",
            "63fb25084c9d43aa87949374094d6bc8",
            "19279e8654f941c4b0bab95c91e15ca6"
          ]
        },
        "id": "D4ARWQpTEg0-",
        "outputId": "182b7ab5-160c-4eb5-b789-3f20d5f0621d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained Wav2Vec2 model and processor.\n",
            "\n",
            " Built dataset_test with 2620 utterances.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=4):   0%|          | 0/2620 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93d3add8da3e48fb81ba67a8833b722b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
            "/usr/local/lib/python3.11/dist-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
            "  table = cls._concat_blocks(blocks, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Preprocessing complete (mapped input_values + labels).\n",
            "\n",
            "\n",
            " Baseline WER (pretrained facebook/wav2vec2-base-960h): 0.038\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show a few examples\n",
        "for idx in [15, 100, 1000]:\n",
        "    print(f\"— idx={idx}\")\n",
        "    print(f\"  REF = {references[idx]}\")\n",
        "    print(f\"  HYP = {predictions[idx]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3svxONq5IK48",
        "outputId": "58419595-a4ed-4b81-89d1-994f3e0abd12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "— idx=15\n",
            "  REF = BUT THE DUSK DEEPENING IN THE SCHOOLROOM COVERED OVER HIS THOUGHTS THE BELL RANG\n",
            "  HYP = BUT THE DUSK DEEPENING IN THE SCHOOLROOM COVERED OVER HIS THOUGHTS THE BELL RANG\n",
            "\n",
            "— idx=100\n",
            "  REF = IN BOTH THESE HIGH MYTHICAL SUBJECTS THE SURROUNDING NATURE THOUGH SUFFERING IS STILL DIGNIFIED AND BEAUTIFUL\n",
            "  HYP = IN BOTH THESE HIGH MYTHICAL SUBJECTS THE SURROUNDING NATURE THOSE SUFFERING IS STILL DIGNIFIED AND BEAUTIFUL\n",
            "\n",
            "— idx=1000\n",
            "  REF = OF THIS SECOND LETTER ALSO SHE SPOKE AND TOLD ME THAT IT CONTAINED AN INVITATION FOR HER TO GO AND SEE THE POET IF EVER SHE VISITED THE LAKES\n",
            "  HYP = OF THIS SECOND LETTER ALSO SHE SPOKE AND TOLD ME THAT IT CONTAINED AN INVITATION FOR HER TO GO AND SEE THE POET IF EVER SHE VISITED THE LAKES\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell H: Save Model and Processor for FastAPI Deployment ===\n",
        "\n",
        "# Set the output path (can be your Drive or any local folder)\n",
        "export_dir = \"/content/drive/MyDrive/LibriSpeech/wav2vec2-fastapi\"\n",
        "\n",
        "# Save both processor and model\n",
        "processor.save_pretrained(export_dir)\n",
        "model.save_pretrained(export_dir)\n",
        "\n",
        "print(f\"✅ Model and processor saved to: {export_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7radHTBd_YA",
        "outputId": "548f3031-4538-4354-bd23-35ac38614a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and processor saved to: /content/drive/MyDrive/LibriSpeech/wav2vec2-fastapi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Paths\n",
        "LIBRISPEECH_ROOT = \"/content\"\n",
        "TRAIN_SUBSET = \"/content/LibriSpeech/train-clean-100\"\n",
        "TEST_SUBSET = \"/content/LibriSpeech/test-clean\"\n",
        "model_name = \"facebook/wav2vec2-base-960h\"\n",
        "\n",
        "# Load processor and fresh model for fine-tuning\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model_ft = Wav2Vec2ForCTC.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRBbWNvmIu8j",
        "outputId": "ef106ee9-0f12-4060-e9ac-0d8f9899e732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Prepare train-clean-100 Dataset ===\n",
        "# Build DataFrame from torchaudio's loader\n",
        "train_rows = []\n",
        "loader_train = LIBRISPEECH(root=LIBRISPEECH_ROOT, url=\"train-clean-100\", download=False)\n",
        "\n",
        "for waveform, sr, transcript, speaker_id, chapter_id, utterance_id in loader_train:\n",
        "    filename = f\"{speaker_id}-{chapter_id}-{utterance_id:04d}.flac\"\n",
        "    flac_path = os.path.join(TRAIN_SUBSET, str(speaker_id), str(chapter_id), filename)\n",
        "    train_rows.append({\"audio_path\": flac_path, \"transcript\": transcript})\n",
        "\n",
        "train_df = pd.DataFrame(train_rows)\n",
        "dataset_train = Dataset.from_pandas(train_df)\n",
        "dataset_train = dataset_train.cast_column(\"audio_path\", Audio(sampling_rate=16000))\n",
        "dataset_train = dataset_train.rename_column(\"audio_path\", \"audio\")\n",
        "dataset_train = dataset_train.rename_column(\"transcript\", \"text\")\n",
        "\n",
        "# Same for test-clean (again, from scratch)\n",
        "test_rows = []\n",
        "loader_test = LIBRISPEECH(root=LIBRISPEECH_ROOT, url=\"test-clean\", download=False)\n",
        "\n",
        "for waveform, sr, transcript, speaker_id, chapter_id, utterance_id in loader_test:\n",
        "    filename = f\"{speaker_id}-{chapter_id}-{utterance_id:04d}.flac\"\n",
        "    flac_path = os.path.join(TEST_SUBSET, str(speaker_id), str(chapter_id), filename)\n",
        "    test_rows.append({\"audio_path\": flac_path, \"transcript\": transcript})\n",
        "\n",
        "test_df = pd.DataFrame(test_rows)\n",
        "dataset_test = Dataset.from_pandas(test_df)\n",
        "dataset_test = dataset_test.cast_column(\"audio_path\", Audio(sampling_rate=16000))\n",
        "dataset_test = dataset_test.rename_column(\"audio_path\", \"audio\")\n",
        "dataset_test = dataset_test.rename_column(\"transcript\", \"text\")\n"
      ],
      "metadata": {
        "id": "99wrpTVHIu42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===  RAM-Safe Preprocessing ===\n",
        "# Only use first 2000 training samples for now\n",
        "\n",
        "def prepare_batch(batch):\n",
        "    audio = batch[\"audio\"][\"array\"]\n",
        "    batch[\"input_values\"] = processor(audio, sampling_rate=16000).input_values[0]\n",
        "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
        "    return batch\n",
        "\n",
        "# ✅ Select a small subset from train-clean-100\n",
        "dataset_train = dataset_train.select(range(2000))   # safe size for Colab\n",
        "\n",
        "# ✅ Keep full test-clean (small enough to fit)\n",
        "dataset_train = dataset_train.map(prepare_batch, remove_columns=[\"audio\", \"text\"])\n",
        "dataset_test  = dataset_test.map(prepare_batch, remove_columns=[\"audio\", \"text\"])\n",
        "\n",
        "print(\"✅ Preprocessing complete (subset of train, full test)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "b5070204b9f2462f9c04210a1edb0afc",
            "a6b6e2223d3d443ea42f7e66fc3312de",
            "474994f8c7954fa9a74ba11c2f65a3c5",
            "60712fc6545c411e8b859a2a41cc42c6",
            "611003a42b3d45deb1cdfb9368161a63",
            "cffb94c7c042462e86d785a93a7c71d0",
            "4538fb65ba9c4d60ab84e62266490256",
            "c98c462feae44db5afac21867ddbb070",
            "6819e6d566db4a03aef4a7e8a3dde232",
            "4e4cfd8c4aba4f848615da7b23213bc6",
            "04b03ed2bda34fdba3009d298168245b",
            "9a4780fdba5b44bca5e1f004bd79f11c",
            "20004c322b824beba0539b58940a58b1",
            "9bf3fdd6a7ca4b349dd3fc2c3a9c5bed",
            "7b98b3af362946939d33369905142e4f",
            "10bf43ce346149f9bf60b2df8b572dc6",
            "bf19db67a7bc44899dcd274a5bd843a2",
            "a5c052b32bce4cab8511ce36155fd9ed",
            "ac4f8e0ad3604546bbd24f0be110b5b9",
            "3c92c4fd8ca0435988e025a2861eeaaf",
            "d08a4fbde89840bdabc65e8d85bb60d6",
            "d21a395592f343e789907fdf8e14078d"
          ]
        },
        "id": "tfO2XHnxIu27",
        "outputId": "6b136649-03e0-45d9-c330-bb8cce343ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5070204b9f2462f9c04210a1edb0afc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2620 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a4780fdba5b44bca5e1f004bd79f11c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing complete (subset of train, full test)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n"
      ],
      "metadata": {
        "id": "b6I0HrEAY276"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell D: Data Collator (for padding) ===\n",
        "from dataclasses import dataclass  # ✅ Required for @dataclass\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    processor: Wav2Vec2Processor\n",
        "    padding: bool = True\n",
        "\n",
        "    def __call__(self, features):\n",
        "        input_features = [{\"input_values\": f[\"input_values\"]} for f in features]\n",
        "        label_features = [{\"input_ids\": f[\"labels\"]} for f in features]\n",
        "\n",
        "        batch = self.processor.feature_extractor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        with self.processor.as_target_processor():\n",
        "            labels_batch = self.processor.tokenizer.pad(\n",
        "                label_features,\n",
        "                padding=self.padding,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "\n",
        "        # Replace padding tokens with -100\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
        "            labels_batch[\"attention_mask\"].ne(1), -100\n",
        "        )\n",
        "        batch[\"labels\"] = labels\n",
        "        return batch\n",
        "\n",
        "# ✅ Instantiate the collator\n",
        "data_collator = DataCollatorCTCWithPadding(processor=processor)\n"
      ],
      "metadata": {
        "id": "ltW31ZLLJ_pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell E: WER Evaluation Function ===\n",
        "wer_metric = evaluate.load(\"wer\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    pred_ids = np.argmax(pred.predictions, axis=-1)\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    label_ids = pred.label_ids\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(label_ids, group_tokens=False)\n",
        "    return {\"wer\": wer_metric.compute(predictions=pred_str, references=label_str)}\n"
      ],
      "metadata": {
        "id": "NU2nT9m8KBbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqF5NUcudSQG",
        "outputId": "29134ad7-caaf-48a6-ca3d-41c0e757ef53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n"
      ],
      "metadata": {
        "id": "BiK2IFtmiSQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./test\",\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "print(\"TrainingArguments works!\")\n"
      ],
      "metadata": {
        "id": "bWoBU7Hwmgld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell F: TrainingArguments and Trainer ===\n",
        "from transformers import TrainingArguments, Trainer  #  Make sure this is imported\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/LibriSpeech/finetuned-wav2vec2\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    evaluation_strategy=\"epoch\",  #  Requires correct transformers version\n",
        "    num_train_epochs=3,\n",
        "    gradient_accumulation_steps=4,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    learning_rate=1e-4,\n",
        "    logging_steps=100,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_ft,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset_train,\n",
        "    eval_dataset=dataset_test,\n",
        "    tokenizer=processor.feature_extractor,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "metadata": {
        "id": "dzq_tsfNJ_sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Cell G: Start Fine-Tuning ===\n",
        "trainer.train()\n",
        "trainer.save_model(output_dir)\n",
        "print(f\" Fine-tuned model saved to: {output_dir}\")\n"
      ],
      "metadata": {
        "id": "d7zm9O4eIu1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn transformers torchaudio soundfile python-multipart\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7d1fq_enpov",
        "outputId": "124a5fab-6505-4e22-bdfa-f8fb1ae49a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.40.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.2.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from torchaudio) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (1.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->torchaudio) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "# Assuming you already have 'model' and 'processor' loaded from training\n",
        "export_dir = \"/content/wav2vec2-fastapi\"\n",
        "\n",
        "#  Save processor and model (creates preprocessor_config.json too)\n",
        "processor.save_pretrained(export_dir)\n",
        "model.save_pretrained(export_dir)\n",
        "\n",
        "#  Confirm files\n",
        "import os\n",
        "print(\"Saved files:\", os.listdir(export_dir))\n"
      ],
      "metadata": {
        "id": "LCT-jmfluBRT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}